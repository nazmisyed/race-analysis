{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "class WebScraper:\n",
    "    \"\"\"\n",
    "    A class for scraping data from web pages.\n",
    "\n",
    "    Attributes:\n",
    "        start_url (str): The URL of the web page to scrape.\n",
    "        soup (BeautifulSoup): The BeautifulSoup object representing the parsed HTML content.\n",
    "        tables (list): A list of BeautifulSoup Tag objects representing the tables in the web page.\n",
    "\n",
    "    Methods:\n",
    "        fetch_data(): Fetches the HTML content of the web page and parses it using BeautifulSoup.\n",
    "        get_data_table(): Retrieves the data table from the web page.\n",
    "        get_page_list(): Retrieves the list of URLs from the web page.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start_url):\n",
    "        self.start_url = start_url\n",
    "        self.base_url = \"\"\n",
    "        # Initialize variables\n",
    "        self.soup = None\n",
    "        self.tables = []\n",
    "        self.data = None  # This will store the dataframe\n",
    "        self.other_pages_url = []\n",
    "        self.get_base_url()\n",
    "        self.fetch_data()\n",
    "\n",
    "    def fetch_data(self):\n",
    "        \"\"\"\n",
    "        Fetches the HTML content of the web page and parses it using BeautifulSoup.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.start_url)\n",
    "            response.raise_for_status()  # Raise an exception if the request was unsuccessful\n",
    "            self.soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            self.tables = self.soup.find_all(\"table\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching URL: {e}\")\n",
    "\n",
    "    def get_base_url(self):\n",
    "        \"\"\"\n",
    "        Removes the strings after \".com/\" in a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to process.\n",
    "\n",
    "        Returns:\n",
    "            str: The URL with the strings after \".com/\" removed.\n",
    "        \"\"\"\n",
    "        index = self.start_url.find(\".com/\")\n",
    "        if index != -1:\n",
    "            self.base_url = self.start_url[:index + 5]\n",
    "        else:\n",
    "            self.base_url = self.start_url\n",
    "\n",
    "\n",
    "    def get_data_table(self):\n",
    "        \"\"\"\n",
    "        Retrieves the data table from the web page.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The data table as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        # Assuming the first table is the data table\n",
    "        if len(self.tables) < 2:\n",
    "            print(\"Data table not found.\")\n",
    "            return None\n",
    "        rows = self.tables[1].find_all(\"tr\")\n",
    "        rows_list = []\n",
    "        for row in rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            cols_list = [col.text for col in cols if \"d-sm-none\" not in col.get(\"class\", [])]\n",
    "            if cols_list:  # Ensure the list is not empty\n",
    "                rows_list.append(cols_list)\n",
    "        if not rows_list:\n",
    "            print(\"No data found in the table.\")\n",
    "            return None\n",
    "        df = pd.DataFrame(rows_list)\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.iloc[1:, :]\n",
    "        return df\n",
    "\n",
    "    def get_page_list(self):\n",
    "        \"\"\"\n",
    "        Retrieves the list of URLs from the web page.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of URLs.\n",
    "        \"\"\"\n",
    "        # Assuming the first table contains links to other pages\n",
    "        if not self.tables:\n",
    "            print(\"No tables found.\")\n",
    "            return None\n",
    "        links = [a['href'] for a in self.tables[0].find_all(\"a\", href=True)]\n",
    "        if not links:\n",
    "            print(\"No URLs found.\")\n",
    "            return None\n",
    "        # You might want to handle relative URLs here   \n",
    "        links_updated = []\n",
    "        for link in links:\n",
    "            links_updated.append(self.base_url + link)\n",
    "\n",
    "\n",
    "        self.other_pages_url = links_updated\n",
    "        return links_updated\n",
    "\n",
    "class PageIterator(WebScraper):\n",
    "    \"\"\"\n",
    "    A class that iterates through a list of page URLs and fetches data tables from each page.\n",
    "\n",
    "    Attributes:\n",
    "    - page_list (list): A list of page URLs to iterate through.\n",
    "    - current_page (int): The index of the current page being processed.\n",
    "    - tables (list): A list to store all tables from all pages.\n",
    "\n",
    "    Methods:\n",
    "    - __init__(self, urls): Initializes the PageIterator object with a list of page URLs.\n",
    "    - fetch_all_pages(self): Fetches data tables from all pages in the page_list.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, urls):\n",
    "        self.page_list = urls\n",
    "        self.current_page = 0\n",
    "        self.tables = []  # Store all tables from all pages\n",
    "        self.fetch_all_pages()\n",
    "\n",
    "    def fetch_all_pages(self):\n",
    "        \"\"\"\n",
    "        Fetches data tables from all pages in the page_list.\n",
    "\n",
    "        Returns:\n",
    "        - tables (list): A list of data tables fetched from all pages.\n",
    "        \"\"\"\n",
    "        for page_url in self.page_list:\n",
    "            self.web_scraper = WebScraper(page_url)\n",
    "            table = self.web_scraper.get_data_table()\n",
    "            if table is not None:\n",
    "                self.tables.append(table)\n",
    "\n",
    "        if len(self.tables) == 0:\n",
    "            print(\"No tables found.\")\n",
    "\n",
    "        return self.tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://runnersunite.racetecresults.com/results.aspx?CId=16634&RId=1189&EId=2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Race No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cat Pos</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Gen Pos</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>HARITH AIMAN ADHA BIN NORASLI</td>\n",
       "      <td>00:14:28</td>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Kujira Swim Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>624</td>\n",
       "      <td>CASEY CHUA YU TONG</td>\n",
       "      <td>00:15:02</td>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore Sports School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>727</td>\n",
       "      <td>ZACHARY CHEW JING HSUAN</td>\n",
       "      <td>00:15:03</td>\n",
       "      <td>open</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>Singapore Sports School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>633</td>\n",
       "      <td>EGAN CHIN JIA YU</td>\n",
       "      <td>00:15:14</td>\n",
       "      <td>open</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>Singapore Sports School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>620</td>\n",
       "      <td>AW JIAN TING</td>\n",
       "      <td>00:15:47</td>\n",
       "      <td>open</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>The Academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105</td>\n",
       "      <td>641</td>\n",
       "      <td>ISAAC CHAN</td>\n",
       "      <td>00:41:02</td>\n",
       "      <td>open</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106</td>\n",
       "      <td>649</td>\n",
       "      <td>KHAIRUN HANI NATASYA BINTI ZAKARIA</td>\n",
       "      <td>00:41:22</td>\n",
       "      <td>open</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107</td>\n",
       "      <td>635</td>\n",
       "      <td>FATEH BAIHAQI BIN MOHD ZAIDI</td>\n",
       "      <td>00:42:30</td>\n",
       "      <td>open</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>67</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108</td>\n",
       "      <td>673</td>\n",
       "      <td>MUHAMMAD EMIR FIRDAUS BIN AHMAD MULANA</td>\n",
       "      <td>00:43:31</td>\n",
       "      <td>open</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>Mya Swimming Academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>109</td>\n",
       "      <td>651</td>\n",
       "      <td>LEE JIAW WEE</td>\n",
       "      <td>00:46:32</td>\n",
       "      <td>open</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0   Pos Race No                                     Name      Time Category  \\\n",
       "1     1     639           HARITH AIMAN ADHA BIN NORASLI   00:14:28     open   \n",
       "2     2     624                      CASEY CHUA YU TONG   00:15:02     open   \n",
       "3     3     727                 ZACHARY CHEW JING HSUAN   00:15:03     open   \n",
       "4     4     633                        EGAN CHIN JIA YU   00:15:14     open   \n",
       "5     5     620                            AW JIAN TING   00:15:47     open   \n",
       "..  ...     ...                                      ...       ...      ...   \n",
       "5   105     641                              ISAAC CHAN   00:41:02     open   \n",
       "6   106     649      KHAIRUN HANI NATASYA BINTI ZAKARIA   00:41:22     open   \n",
       "7   107     635            FATEH BAIHAQI BIN MOHD ZAIDI   00:42:30     open   \n",
       "8   108     673  MUHAMMAD EMIR FIRDAUS BIN AHMAD MULANA   00:43:31     open   \n",
       "9   109     651                            LEE JIAW WEE   00:46:32     open   \n",
       "\n",
       "0  Cat Pos  Gender Gen Pos                     Team  \n",
       "1        1    Male       1         Kujira Swim Club  \n",
       "2        1  Female       1  Singapore Sports School  \n",
       "3        2    Male       2  Singapore Sports School  \n",
       "4        3    Male       3  Singapore Sports School  \n",
       "5        4    Male       4              The Academy  \n",
       "..     ...     ...     ...                      ...  \n",
       "5       66    Male      66                           \n",
       "6       40  Female      40                           \n",
       "7       67    Male      67                           \n",
       "8       68    Male      68     Mya Swimming Academy  \n",
       "9       69    Male      69                           \n",
       "\n",
       "[109 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a WebScraper object with the start URL\n",
    "km1 = WebScraper(start_url=url)\n",
    "\n",
    "# Get the data table from the start URL\n",
    "data = km1.get_data_table()\n",
    "\n",
    "# Get the list of other pages to scrape\n",
    "page_list = km1.get_page_list()\n",
    "\n",
    "# Create a PageIterator object with the list of pages\n",
    "other_data = PageIterator(page_list)\n",
    "\n",
    "# Get the tables from the other pages\n",
    "all_data = other_data.tables\n",
    "\n",
    "# Append the data table from the start URL to the list of all data tables\n",
    "all_data.append(data)\n",
    "\n",
    "# Concatenate all data tables into a single DataFrame\n",
    "df_all = pd.concat(all_data)\n",
    "\n",
    "# Remove rows where the 'Pos' column is empty\n",
    "df_all = df_all[df_all['Pos'] != '']\n",
    "\n",
    "# Convert the 'Pos' column to integer type\n",
    "df_all['Pos'] = df_all['Pos'].astype(int)\n",
    "\n",
    "# Sort the DataFrame by the 'Pos' column\n",
    "df_all = df_all.sort_values(by=['Pos'])\n",
    "\n",
    "# Remove rows where the 'Time' column does not contain a colon (i.e., is not in HH:MM:SS format)\n",
    "df_all = df_all[df_all['Time'].str.contains(':')]\n",
    "\n",
    "# Remove leading and trailing whitespace from the 'Team' column\n",
    "df_all[\"Team\"] = df_all[\"Team\"].str.strip()\n",
    "\n",
    "# Replace \"N/A\" with an empty string in the 'Team' column\n",
    "df_all[\"Team\"] = df_all[\"Team\"].str.replace(\"N/A\", \"\")\n",
    "\n",
    "#Remove uneccessary Column\n",
    "df_all = df_all.drop('Fav', axis=1)\n",
    "df_all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the file to csv. the format should be [eventname]_[startdate]_[category].csv\n",
    "eventname = \"ThistlePDOWSClassic\"\n",
    "startdate = \"20240203\"\n",
    "category = \"1k\"\n",
    "df_all.to_csv(f\"../Dataset/{eventname}_{startdate}_{category}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
